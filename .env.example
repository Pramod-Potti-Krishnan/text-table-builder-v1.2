# =============================================================================
# Text & Table Builder v1.2 - Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Google Cloud / Vertex AI Configuration
# -----------------------------------------------------------------------------

# REQUIRED: Google Cloud Project ID for Vertex AI
GCP_PROJECT_ID=your-project-id

# OPTIONAL: GCP Location (default: us-central1)
GCP_LOCATION=us-central1

# OPTIONAL: Service Account JSON (for Railway/Production)
# For local development, use Application Default Credentials (gcloud auth application-default login)
# For production, set this to the full JSON string of your service account key
GCP_SERVICE_ACCOUNT_JSON=

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------

# LLM Provider (gemini, openai, anthropic)
LLM_PROVIDER=gemini

# Gemini Model Names
GEMINI_FLASH_MODEL=gemini-2.0-flash-exp
GEMINI_PRO_MODEL=gemini-1.5-pro

# Model Selection Strategy
# Enable automatic routing: Flash for simple elements, Pro for complex
ENABLE_MODEL_ROUTING=true

# Generation Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=8192

# -----------------------------------------------------------------------------
# v1.2 Architecture Configuration
# -----------------------------------------------------------------------------

# Parallel Element Generation
ENABLE_PARALLEL_GENERATION=true
MAX_PARALLEL_WORKERS=5

# Character Count Validation
ENABLE_CHARACTER_VALIDATION=true

# Template Caching
ENABLE_TEMPLATE_CACHING=true

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------

# FastAPI Settings
API_HOST=0.0.0.0
API_PORT=8100
API_RELOAD=true

# Logging
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Usage Notes
# -----------------------------------------------------------------------------

# Local Development Setup:
# 1. Install Google Cloud SDK: https://cloud.google.com/sdk/docs/install
# 2. Authenticate: gcloud auth application-default login
# 3. Set project: gcloud config set project YOUR_PROJECT_ID
# 4. Copy this file to .env and set GCP_PROJECT_ID
# 5. Run: uvicorn main:app --reload

# Production/Railway Setup:
# 1. Create a service account in Google Cloud Console
# 2. Grant "Vertex AI User" role to the service account
# 3. Download the service account JSON key
# 4. Set GCP_SERVICE_ACCOUNT_JSON environment variable to the JSON content
# 5. Set GCP_PROJECT_ID environment variable

# Model Routing Strategy:
# - SIMPLE elements (text_box, metric_card, quote): Use Flash (fast, cheap)
# - COMPLEX elements (table, comparison, multi-section): Use Pro (better quality)
# - Typical cost savings: 60-70% compared to using Pro for everything

# Parallel Generation Performance:
# - Sequential: ~4.2s for 4 elements
# - Parallel (5 workers): ~1.1s for 4 elements
# - 3.8x speedup with parallel processing
